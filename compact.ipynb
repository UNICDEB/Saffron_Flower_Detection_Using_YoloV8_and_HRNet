{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9e8e08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30ce7b18",
   "metadata": {},
   "source": [
    "Only keep YOLO detections if confidence > 0.30 (30%).\n",
    "\n",
    "This should apply for both classes (top = 0, side = 1).\n",
    "\n",
    "If below threshold → ignore that detection.\n",
    "\n",
    "Here’s the updated compact YOLO + HRNet pipeline with confidence check:\n",
    "\n",
    "\n",
    "Output:\n",
    "Top view (class 0) → only bbox.\n",
    "\n",
    "Side view (class 1) → bbox + HRNet plucking point in red."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbc2cb3",
   "metadata": {},
   "source": [
    "#### For Single Image Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55d3bc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tecte\\anaconda3\\envs\\yolov11_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'HRNet' from 'train_hrnet_pluck' (e:\\Project_Work\\2025\\Saffron_Project\\Github_Code\\Saffron_Detection\\YoloV8+HRNet\\train_hrnet_pluck.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01multralytics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtrain_hrnet_pluck\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HRNet, preprocess_img\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# -------------------------------\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# CONFIG\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# -------------------------------\u001b[39;00m\n\u001b[32m     11\u001b[39m yolo_model_path = \u001b[33m\"\u001b[39m\u001b[33mE:/Project_Work/2025/Saffron_Project/Github_Code/Saffron_Detection/YoloV8+HRNet/YoloV8_Result_Object_detection/Result_Weight/detect/weights/best.pt\u001b[39m\u001b[33m\"\u001b[39m   \u001b[38;5;66;03m# YOLOv8 weights\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'HRNet' from 'train_hrnet_pluck' (e:\\Project_Work\\2025\\Saffron_Project\\Github_Code\\Saffron_Detection\\YoloV8+HRNet\\train_hrnet_pluck.py)"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "from train_hrnet_pluck import HRNet, preprocess_img\n",
    "\n",
    "# -------------------------------\n",
    "# CONFIG\n",
    "# -------------------------------\n",
    "yolo_model_path = \"E:/Project_Work/2025/Saffron_Project/Github_Code/Saffron_Detection/YoloV8+HRNet/YoloV8_Result_Object_detection/Result_Weight/detect/weights/best.pt\"   # YOLOv8 weights\n",
    "hrnet_model_path = \"hrnet_pluck_best.pth\"              # HRNet weights\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "img_size = 640\n",
    "conf_thresh = 0.30   # confidence threshold (30%)\n",
    "\n",
    "# -------------------------------\n",
    "# LOAD MODELS\n",
    "# -------------------------------\n",
    "yolo = YOLO(yolo_model_path)\n",
    "\n",
    "hrnet = HRNet(num_keypoints=1)\n",
    "hrnet.load_state_dict(torch.load(hrnet_model_path, map_location=device))\n",
    "hrnet.to(device).eval()\n",
    "\n",
    "# -------------------------------\n",
    "# HRNet PREDICTION FUNCTION\n",
    "# -------------------------------\n",
    "def predict_pluck_point(crop_img):\n",
    "    img = preprocess_img(crop_img, img_size).to(device)\n",
    "    with torch.no_grad():\n",
    "        out = hrnet(img).cpu().numpy()[0]\n",
    "    px, py = out[0], out[1]   # normalized coords (0-1)\n",
    "    return px, py\n",
    "\n",
    "# -------------------------------\n",
    "# YOLO + HRNet PIPELINE\n",
    "# -------------------------------\n",
    "def run_pipeline(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    results = yolo.predict(image_path, device=device, verbose=False)[0]\n",
    "\n",
    "    for box in results.boxes:\n",
    "        conf = float(box.conf[0].item())\n",
    "        cls = int(box.cls[0].item())\n",
    "        if conf < conf_thresh:   # skip low confidence\n",
    "            continue\n",
    "\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
    "\n",
    "        # Draw YOLO bbox\n",
    "        cv2.rectangle(img, (x1,y1), (x2,y2), (0,255,0), 2)\n",
    "        label = f\"{'top' if cls==0 else 'side'} ({conf:.2f})\"\n",
    "        cv2.putText(img, label, (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    0.7, (0,255,0), 2)\n",
    "\n",
    "        # If side flower → HRNet plucking point\n",
    "        if cls == 1:\n",
    "            crop = img[y1:y2, x1:x2]\n",
    "            px, py = predict_pluck_point(crop)\n",
    "\n",
    "            # Convert back to absolute coords on original image\n",
    "            cx = int(x1 + px * (x2 - x1))\n",
    "            cy = int(y1 + py * (y2 - y1))\n",
    "\n",
    "            # Draw point\n",
    "            cv2.circle(img, (cx, cy), 6, (0,0,255), -1)\n",
    "            cv2.putText(img, \"Pluck\", (cx+5, cy), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.6, (0,0,255), 2)\n",
    "\n",
    "    # Show final result\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# -------------------------------\n",
    "# RUN\n",
    "# -------------------------------\n",
    "run_pipeline(\"test.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1da1566",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71375efb",
   "metadata": {},
   "source": [
    "#### For Multiple Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f87d147",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tecte\\AppData\\Local\\Temp\\ipykernel_21768\\3396549511.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(hrnet_model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 2 Saffron_Sides, 114.4ms\n",
      "Speed: 28.1ms preprocess, 114.4ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_12.jpeg -> output_results\\image_12.jpeg\n",
      "\n",
      "0: 480x640 5 Saffron_Sides, 12.8ms\n",
      "Speed: 1.3ms preprocess, 12.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_13.jpeg -> output_results\\image_13.jpeg\n",
      "\n",
      "0: 480x640 6 Saffron_Sides, 13.0ms\n",
      "Speed: 2.2ms preprocess, 13.0ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_15.jpeg -> output_results\\image_15.jpeg\n",
      "\n",
      "0: 480x640 5 Saffron_Sides, 12.9ms\n",
      "Speed: 1.3ms preprocess, 12.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_17.jpeg -> output_results\\image_17.jpeg\n",
      "\n",
      "0: 640x480 6 Saffron_Sides, 56.3ms\n",
      "Speed: 1.6ms preprocess, 56.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processed: image_19.jpeg -> output_results\\image_19.jpeg\n",
      "\n",
      "0: 480x640 3 Saffron_Sides, 14.0ms\n",
      "Speed: 1.7ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_20.jpeg -> output_results\\image_20.jpeg\n",
      "\n",
      "0: 480x640 5 Saffron_Sides, 12.9ms\n",
      "Speed: 1.4ms preprocess, 12.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_22.jpeg -> output_results\\image_22.jpeg\n",
      "\n",
      "0: 480x640 4 Saffron_Sides, 12.8ms\n",
      "Speed: 1.4ms preprocess, 12.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_23.jpeg -> output_results\\image_23.jpeg\n",
      "\n",
      "0: 480x640 1 Saffron_Top, 3 Saffron_Sides, 12.7ms\n",
      "Speed: 1.3ms preprocess, 12.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_24.jpeg -> output_results\\image_24.jpeg\n",
      "\n",
      "0: 480x640 3 Saffron_Sides, 12.8ms\n",
      "Speed: 1.4ms preprocess, 12.8ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_26.jpeg -> output_results\\image_26.jpeg\n",
      "\n",
      "0: 480x640 7 Saffron_Sides, 13.2ms\n",
      "Speed: 1.4ms preprocess, 13.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_29.jpeg -> output_results\\image_29.jpeg\n",
      "\n",
      "0: 480x640 1 Saffron_Side, 12.7ms\n",
      "Speed: 1.2ms preprocess, 12.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_31.jpeg -> output_results\\image_31.jpeg\n",
      "\n",
      "0: 480x640 1 Saffron_Top, 5 Saffron_Sides, 12.9ms\n",
      "Speed: 1.2ms preprocess, 12.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_32.jpeg -> output_results\\image_32.jpeg\n",
      "\n",
      "0: 480x640 4 Saffron_Sides, 12.8ms\n",
      "Speed: 1.8ms preprocess, 12.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_33.jpeg -> output_results\\image_33.jpeg\n",
      "\n",
      "0: 480x640 8 Saffron_Sides, 13.0ms\n",
      "Speed: 1.3ms preprocess, 13.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_35.jpeg -> output_results\\image_35.jpeg\n",
      "\n",
      "0: 480x640 5 Saffron_Sides, 12.8ms\n",
      "Speed: 1.4ms preprocess, 12.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_36.jpeg -> output_results\\image_36.jpeg\n",
      "\n",
      "0: 480x640 6 Saffron_Sides, 12.9ms\n",
      "Speed: 1.2ms preprocess, 12.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_37.jpeg -> output_results\\image_37.jpeg\n",
      "\n",
      "0: 480x640 2 Saffron_Sides, 12.8ms\n",
      "Speed: 1.2ms preprocess, 12.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_38.jpeg -> output_results\\image_38.jpeg\n",
      "\n",
      "0: 480x640 3 Saffron_Sides, 12.9ms\n",
      "Speed: 1.3ms preprocess, 12.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_40.jpeg -> output_results\\image_40.jpeg\n",
      "\n",
      "0: 480x640 5 Saffron_Sides, 13.3ms\n",
      "Speed: 1.3ms preprocess, 13.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_41.jpeg -> output_results\\image_41.jpeg\n",
      "\n",
      "0: 480x640 2 Saffron_Sides, 13.2ms\n",
      "Speed: 1.1ms preprocess, 13.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_42.jpeg -> output_results\\image_42.jpeg\n",
      "\n",
      "0: 480x640 3 Saffron_Sides, 13.2ms\n",
      "Speed: 1.2ms preprocess, 13.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_45.jpeg -> output_results\\image_45.jpeg\n",
      "\n",
      "0: 480x640 1 Saffron_Side, 13.4ms\n",
      "Speed: 1.1ms preprocess, 13.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_46.jpeg -> output_results\\image_46.jpeg\n",
      "\n",
      "0: 480x640 2 Saffron_Sides, 13.1ms\n",
      "Speed: 1.2ms preprocess, 13.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_47.jpeg -> output_results\\image_47.jpeg\n",
      "\n",
      "0: 480x640 1 Saffron_Top, 5 Saffron_Sides, 13.2ms\n",
      "Speed: 1.1ms preprocess, 13.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_48.jpeg -> output_results\\image_48.jpeg\n",
      "\n",
      "0: 480x640 7 Saffron_Sides, 13.1ms\n",
      "Speed: 1.3ms preprocess, 13.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_49.jpeg -> output_results\\image_49.jpeg\n",
      "\n",
      "0: 480x640 3 Saffron_Sides, 12.9ms\n",
      "Speed: 1.1ms preprocess, 12.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_50.jpeg -> output_results\\image_50.jpeg\n",
      "\n",
      "0: 480x640 4 Saffron_Sides, 12.8ms\n",
      "Speed: 1.2ms preprocess, 12.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_51.jpeg -> output_results\\image_51.jpeg\n",
      "\n",
      "0: 480x640 2 Saffron_Sides, 12.9ms\n",
      "Speed: 1.2ms preprocess, 12.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_54.jpeg -> output_results\\image_54.jpeg\n",
      "\n",
      "0: 480x640 3 Saffron_Sides, 12.8ms\n",
      "Speed: 1.1ms preprocess, 12.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_55.jpeg -> output_results\\image_55.jpeg\n",
      "\n",
      "0: 480x640 5 Saffron_Sides, 13.0ms\n",
      "Speed: 1.2ms preprocess, 13.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_58.jpeg -> output_results\\image_58.jpeg\n",
      "\n",
      "0: 480x640 3 Saffron_Sides, 12.8ms\n",
      "Speed: 1.2ms preprocess, 12.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_59.jpeg -> output_results\\image_59.jpeg\n",
      "\n",
      "0: 480x640 3 Saffron_Sides, 14.0ms\n",
      "Speed: 1.1ms preprocess, 14.0ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_60.jpeg -> output_results\\image_60.jpeg\n",
      "\n",
      "0: 480x640 1 Saffron_Top, 7 Saffron_Sides, 12.7ms\n",
      "Speed: 1.1ms preprocess, 12.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_61.jpeg -> output_results\\image_61.jpeg\n",
      "\n",
      "0: 480x640 4 Saffron_Sides, 12.5ms\n",
      "Speed: 1.5ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_62.jpeg -> output_results\\image_62.jpeg\n",
      "\n",
      "0: 480x640 1 Saffron_Side, 12.7ms\n",
      "Speed: 1.2ms preprocess, 12.7ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_65.jpeg -> output_results\\image_65.jpeg\n",
      "\n",
      "0: 480x640 3 Saffron_Tops, 6 Saffron_Sides, 12.4ms\n",
      "Speed: 1.4ms preprocess, 12.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_66.jpeg -> output_results\\image_66.jpeg\n",
      "\n",
      "0: 480x640 6 Saffron_Sides, 12.5ms\n",
      "Speed: 1.2ms preprocess, 12.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_67.jpeg -> output_results\\image_67.jpeg\n",
      "\n",
      "0: 480x640 1 Saffron_Side, 12.5ms\n",
      "Speed: 1.1ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_70.jpeg -> output_results\\image_70.jpeg\n",
      "\n",
      "0: 480x640 2 Saffron_Sides, 12.5ms\n",
      "Speed: 1.2ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_71.jpeg -> output_results\\image_71.jpeg\n",
      "\n",
      "0: 480x640 7 Saffron_Sides, 12.5ms\n",
      "Speed: 1.2ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_72.jpeg -> output_results\\image_72.jpeg\n",
      "\n",
      "0: 480x640 3 Saffron_Sides, 12.6ms\n",
      "Speed: 1.1ms preprocess, 12.6ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_74.jpeg -> output_results\\image_74.jpeg\n",
      "\n",
      "0: 640x512 1 Saffron_Top, 36.7ms\n",
      "Speed: 2.0ms preprocess, 36.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed: IMG20241029122356.jpg -> output_results\\IMG20241029122356.jpg\n",
      "\n",
      "0: 512x640 1 Saffron_Top, 61.8ms\n",
      "Speed: 2.2ms preprocess, 61.8ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Processed: IMG20241029122400.jpg -> output_results\\IMG20241029122400.jpg\n",
      "\n",
      "0: 512x640 1 Saffron_Top, 13.4ms\n",
      "Speed: 2.0ms preprocess, 13.4ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Processed: IMG20241029122404.jpg -> output_results\\IMG20241029122404.jpg\n",
      "\n",
      "0: 640x512 1 Saffron_Top, 14.7ms\n",
      "Speed: 1.8ms preprocess, 14.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed: IMG20241029122428.jpg -> output_results\\IMG20241029122428.jpg\n",
      "\n",
      "0: 640x512 1 Saffron_Top, 13.3ms\n",
      "Speed: 1.7ms preprocess, 13.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed: IMG20241029122442.jpg -> output_results\\IMG20241029122442.jpg\n",
      "\n",
      "0: 640x512 1 Saffron_Top, 13.2ms\n",
      "Speed: 2.1ms preprocess, 13.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed: IMG20241029122445.jpg -> output_results\\IMG20241029122445.jpg\n",
      "\n",
      "0: 640x512 1 Saffron_Top, 21.6ms\n",
      "Speed: 2.3ms preprocess, 21.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed: IMG20241029122447.jpg -> output_results\\IMG20241029122447.jpg\n",
      "\n",
      "0: 640x512 2 Saffron_Tops, 21.7ms\n",
      "Speed: 2.0ms preprocess, 21.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed: IMG20241029122455.jpg -> output_results\\IMG20241029122455.jpg\n",
      "\n",
      "0: 640x512 1 Saffron_Top, 22.1ms\n",
      "Speed: 2.0ms preprocess, 22.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed: IMG20241029122500.jpg -> output_results\\IMG20241029122500.jpg\n",
      "\n",
      "0: 640x512 2 Saffron_Tops, 22.9ms\n",
      "Speed: 2.5ms preprocess, 22.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed: IMG20241029122525.jpg -> output_results\\IMG20241029122525.jpg\n",
      "\n",
      "0: 640x512 (no detections), 23.8ms\n",
      "Speed: 2.2ms preprocess, 23.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed: IMG20241029122620.jpg -> output_results\\IMG20241029122620.jpg\n",
      "\n",
      "0: 640x512 (no detections), 24.3ms\n",
      "Speed: 2.4ms preprocess, 24.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed: IMG20241029122624.jpg -> output_results\\IMG20241029122624.jpg\n",
      "\n",
      "0: 512x640 (no detections), 25.5ms\n",
      "Speed: 2.3ms preprocess, 25.5ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Processed: IMG20241029122629.jpg -> output_results\\IMG20241029122629.jpg\n",
      "\n",
      "0: 512x640 1 Saffron_Top, 25.7ms\n",
      "Speed: 2.2ms preprocess, 25.7ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Processed: IMG20241029122632.jpg -> output_results\\IMG20241029122632.jpg\n",
      "\n",
      "0: 640x512 4 Saffron_Tops, 27.4ms\n",
      "Speed: 2.9ms preprocess, 27.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed: IMG20241029123112.jpg -> output_results\\IMG20241029123112.jpg\n",
      "\n",
      "0: 640x512 5 Saffron_Tops, 27.5ms\n",
      "Speed: 2.1ms preprocess, 27.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed: IMG20241029123145.jpg -> output_results\\IMG20241029123145.jpg\n",
      "\n",
      "0: 640x512 1 Saffron_Top, 27.9ms\n",
      "Speed: 2.2ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed: IMG20241029123149.jpg -> output_results\\IMG20241029123149.jpg\n",
      "\n",
      "0: 640x512 1 Saffron_Top, 29.0ms\n",
      "Speed: 2.6ms preprocess, 29.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed: IMG20241029123513.jpg -> output_results\\IMG20241029123513.jpg\n",
      "✅ All images processed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models import resnet18\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------------\n",
    "# HRNet (simplified resnet backbone)\n",
    "# -------------------------------\n",
    "class HRNet(nn.Module):\n",
    "    def __init__(self, num_keypoints=1):\n",
    "        super(HRNet, self).__init__()\n",
    "        backbone = resnet18(pretrained=True)\n",
    "        self.backbone = nn.Sequential(*list(backbone.children())[:-2])\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Conv2d(512, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, num_keypoints, kernel_size=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        feat = self.backbone(x)\n",
    "        out = self.head(feat)\n",
    "        out = out.mean(dim=[2, 3])  # (B, num_keypoints)\n",
    "        return out\n",
    "\n",
    "def preprocess_img(img, img_size=640):\n",
    "    transform = T.Compose([\n",
    "        T.ToPILImage(),\n",
    "        T.Resize((img_size, img_size)),\n",
    "        T.ToTensor(),\n",
    "    ])\n",
    "    return transform(img).unsqueeze(0)\n",
    "\n",
    "# -------------------------------\n",
    "# CONFIG\n",
    "# -------------------------------\n",
    "yolo_model_path = \"E:/Project_Work/2025/Saffron_Project/Github_Code/Saffron_Detection/YoloV8+HRNet/YoloV8_Result_Object_detection/Result_Weight/detect/weights/best.pt\"\n",
    "hrnet_model_path = \"hrnet_pluck_best.pth\"\n",
    "input_folder = \"E:/Project_Work/2025/Saffron_Project/Github_Code/Saffron_Detection/YoloV8+HRNet/YoloV8_Result_Object_detection/test/images_field\"\n",
    "output_folder = \"output_results\"\n",
    "confidence_thresh = 0.30\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# -------------------------------\n",
    "# LOAD MODELS\n",
    "# -------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load YOLO\n",
    "yolo = YOLO(yolo_model_path)\n",
    "\n",
    "# Load HRNet properly\n",
    "checkpoint = torch.load(hrnet_model_path, map_location=device)\n",
    "state_dict = checkpoint.get(\"model\", checkpoint)  # extract model if checkpoint contains dict\n",
    "hrnet = HRNet(num_keypoints=1).to(device)\n",
    "hrnet.load_state_dict(state_dict, strict=False)\n",
    "hrnet.eval()\n",
    "\n",
    "# -------------------------------\n",
    "# INFERENCE LOOP\n",
    "# -------------------------------\n",
    "for file in os.listdir(input_folder):\n",
    "    if not file.lower().endswith((\".jpg\", \".png\", \".jpeg\")):\n",
    "        continue\n",
    "    \n",
    "    img_path = os.path.join(input_folder, file)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        continue\n",
    "    \n",
    "    # Run YOLO\n",
    "    results = yolo(img)[0]\n",
    "    for i, box in enumerate(results.boxes):\n",
    "        conf = float(box.conf[0])\n",
    "        cls = int(box.cls[0])\n",
    "        if conf < confidence_thresh:\n",
    "            continue\n",
    "        \n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        crop = img[y1:y2, x1:x2]\n",
    "        if crop.size == 0:\n",
    "            continue\n",
    "\n",
    "        # Run HRNet on cropped region\n",
    "        inp = preprocess_img(crop).to(device)\n",
    "        with torch.no_grad():\n",
    "            keypoints = hrnet(inp).cpu().numpy()[0]\n",
    "        # keypoints are normalized (0-1), convert to pixel coords in the crop\n",
    "        cx = int(x1 + keypoints[0] * (x2 - x1))\n",
    "        cy = int(y1 + keypoints[0] * (y2 - y1))  # assuming single keypoint y normalized same as x\n",
    "        # If your training stored x,y separately, adjust this\n",
    "\n",
    "        # Draw bbox + keypoints\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(img, f\"YOLO conf: {conf:.2f}\", (x1, y1 - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        cv2.circle(img, (cx, cy), 5, (0, 0, 255), -1)\n",
    "        cv2.putText(img, \"Pluck\", (cx+5, cy), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5, (0, 0, 255), 2)\n",
    "\n",
    "    # Save result\n",
    "    save_path = os.path.join(output_folder, file)\n",
    "    cv2.imwrite(save_path, img)\n",
    "    print(f\"Processed: {file} -> {save_path}\")\n",
    "\n",
    "print(\"✅ All images processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81cdaad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "807385c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tecte\\AppData\\Local\\Temp\\ipykernel_21768\\3598554995.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(hrnet_model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 2 Saffron_Sides, 13.3ms\n",
      "Speed: 6.8ms preprocess, 13.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_12.jpeg -> output_results\\image_12.jpeg\n",
      "\n",
      "0: 480x640 5 Saffron_Sides, 12.9ms\n",
      "Speed: 1.1ms preprocess, 12.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_13.jpeg -> output_results\\image_13.jpeg\n",
      "\n",
      "0: 480x640 6 Saffron_Sides, 13.7ms\n",
      "Speed: 1.3ms preprocess, 13.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_15.jpeg -> output_results\\image_15.jpeg\n",
      "\n",
      "0: 480x640 5 Saffron_Sides, 11.7ms\n",
      "Speed: 1.1ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_17.jpeg -> output_results\\image_17.jpeg\n",
      "\n",
      "0: 640x480 6 Saffron_Sides, 13.8ms\n",
      "Speed: 1.3ms preprocess, 13.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Processed: image_19.jpeg -> output_results\\image_19.jpeg\n",
      "\n",
      "0: 480x640 3 Saffron_Sides, 12.4ms\n",
      "Speed: 1.3ms preprocess, 12.4ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_20.jpeg -> output_results\\image_20.jpeg\n",
      "\n",
      "0: 480x640 5 Saffron_Sides, 11.7ms\n",
      "Speed: 1.1ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_22.jpeg -> output_results\\image_22.jpeg\n",
      "\n",
      "0: 480x640 4 Saffron_Sides, 11.8ms\n",
      "Speed: 1.2ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_23.jpeg -> output_results\\image_23.jpeg\n",
      "\n",
      "0: 480x640 1 Saffron_Top, 3 Saffron_Sides, 11.7ms\n",
      "Speed: 1.3ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_24.jpeg -> output_results\\image_24.jpeg\n",
      "\n",
      "0: 480x640 3 Saffron_Sides, 11.7ms\n",
      "Speed: 1.1ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_26.jpeg -> output_results\\image_26.jpeg\n",
      "\n",
      "0: 480x640 7 Saffron_Sides, 11.7ms\n",
      "Speed: 1.4ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_29.jpeg -> output_results\\image_29.jpeg\n",
      "\n",
      "0: 480x640 1 Saffron_Side, 11.7ms\n",
      "Speed: 1.4ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_31.jpeg -> output_results\\image_31.jpeg\n",
      "\n",
      "0: 480x640 1 Saffron_Top, 5 Saffron_Sides, 11.7ms\n",
      "Speed: 1.6ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_32.jpeg -> output_results\\image_32.jpeg\n",
      "\n",
      "0: 480x640 4 Saffron_Sides, 11.8ms\n",
      "Speed: 1.2ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_33.jpeg -> output_results\\image_33.jpeg\n",
      "\n",
      "0: 480x640 8 Saffron_Sides, 11.8ms\n",
      "Speed: 1.3ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_35.jpeg -> output_results\\image_35.jpeg\n",
      "\n",
      "0: 480x640 5 Saffron_Sides, 11.7ms\n",
      "Speed: 1.1ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_36.jpeg -> output_results\\image_36.jpeg\n",
      "\n",
      "0: 480x640 6 Saffron_Sides, 11.8ms\n",
      "Speed: 1.1ms preprocess, 11.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_37.jpeg -> output_results\\image_37.jpeg\n",
      "\n",
      "0: 480x640 2 Saffron_Sides, 11.7ms\n",
      "Speed: 1.1ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_38.jpeg -> output_results\\image_38.jpeg\n",
      "\n",
      "0: 480x640 3 Saffron_Sides, 11.7ms\n",
      "Speed: 1.1ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_40.jpeg -> output_results\\image_40.jpeg\n",
      "\n",
      "0: 480x640 5 Saffron_Sides, 11.8ms\n",
      "Speed: 1.3ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_41.jpeg -> output_results\\image_41.jpeg\n",
      "\n",
      "0: 480x640 2 Saffron_Sides, 12.8ms\n",
      "Speed: 1.1ms preprocess, 12.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_42.jpeg -> output_results\\image_42.jpeg\n",
      "\n",
      "0: 480x640 3 Saffron_Sides, 11.7ms\n",
      "Speed: 1.2ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_45.jpeg -> output_results\\image_45.jpeg\n",
      "\n",
      "0: 480x640 1 Saffron_Side, 11.7ms\n",
      "Speed: 1.1ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_46.jpeg -> output_results\\image_46.jpeg\n",
      "\n",
      "0: 480x640 2 Saffron_Sides, 11.7ms\n",
      "Speed: 1.1ms preprocess, 11.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_47.jpeg -> output_results\\image_47.jpeg\n",
      "\n",
      "0: 480x640 1 Saffron_Top, 5 Saffron_Sides, 11.8ms\n",
      "Speed: 1.1ms preprocess, 11.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_48.jpeg -> output_results\\image_48.jpeg\n",
      "\n",
      "0: 480x640 7 Saffron_Sides, 11.7ms\n",
      "Speed: 1.5ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_49.jpeg -> output_results\\image_49.jpeg\n",
      "\n",
      "0: 480x640 3 Saffron_Sides, 12.8ms\n",
      "Speed: 1.1ms preprocess, 12.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_50.jpeg -> output_results\\image_50.jpeg\n",
      "\n",
      "0: 480x640 4 Saffron_Sides, 11.7ms\n",
      "Speed: 1.6ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_51.jpeg -> output_results\\image_51.jpeg\n",
      "\n",
      "0: 480x640 2 Saffron_Sides, 11.6ms\n",
      "Speed: 1.1ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_54.jpeg -> output_results\\image_54.jpeg\n",
      "\n",
      "0: 480x640 3 Saffron_Sides, 11.7ms\n",
      "Speed: 1.1ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_55.jpeg -> output_results\\image_55.jpeg\n",
      "\n",
      "0: 480x640 5 Saffron_Sides, 13.5ms\n",
      "Speed: 1.1ms preprocess, 13.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_58.jpeg -> output_results\\image_58.jpeg\n",
      "\n",
      "0: 480x640 3 Saffron_Sides, 11.7ms\n",
      "Speed: 1.1ms preprocess, 11.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_59.jpeg -> output_results\\image_59.jpeg\n",
      "\n",
      "0: 480x640 3 Saffron_Sides, 11.8ms\n",
      "Speed: 1.7ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_60.jpeg -> output_results\\image_60.jpeg\n",
      "\n",
      "0: 480x640 1 Saffron_Top, 7 Saffron_Sides, 11.7ms\n",
      "Speed: 1.1ms preprocess, 11.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_61.jpeg -> output_results\\image_61.jpeg\n",
      "\n",
      "0: 480x640 4 Saffron_Sides, 11.7ms\n",
      "Speed: 1.2ms preprocess, 11.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_62.jpeg -> output_results\\image_62.jpeg\n",
      "\n",
      "0: 480x640 1 Saffron_Side, 11.7ms\n",
      "Speed: 1.3ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_65.jpeg -> output_results\\image_65.jpeg\n",
      "\n",
      "0: 480x640 3 Saffron_Tops, 6 Saffron_Sides, 12.6ms\n",
      "Speed: 1.8ms preprocess, 12.6ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_66.jpeg -> output_results\\image_66.jpeg\n",
      "\n",
      "0: 480x640 6 Saffron_Sides, 13.9ms\n",
      "Speed: 1.1ms preprocess, 13.9ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_67.jpeg -> output_results\\image_67.jpeg\n",
      "\n",
      "0: 480x640 1 Saffron_Side, 11.8ms\n",
      "Speed: 1.1ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_70.jpeg -> output_results\\image_70.jpeg\n",
      "\n",
      "0: 480x640 2 Saffron_Sides, 14.5ms\n",
      "Speed: 1.3ms preprocess, 14.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_71.jpeg -> output_results\\image_71.jpeg\n",
      "\n",
      "0: 480x640 7 Saffron_Sides, 11.9ms\n",
      "Speed: 1.3ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_72.jpeg -> output_results\\image_72.jpeg\n",
      "\n",
      "0: 480x640 3 Saffron_Sides, 11.7ms\n",
      "Speed: 1.3ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processed: image_74.jpeg -> output_results\\image_74.jpeg\n",
      "\n",
      "0: 640x512 1 Saffron_Top, 13.0ms\n",
      "Speed: 2.5ms preprocess, 13.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed: IMG20241029122356.jpg -> output_results\\IMG20241029122356.jpg\n",
      "\n",
      "0: 512x640 1 Saffron_Top, 13.6ms\n",
      "Speed: 1.9ms preprocess, 13.6ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Processed: IMG20241029122400.jpg -> output_results\\IMG20241029122400.jpg\n",
      "\n",
      "0: 512x640 1 Saffron_Top, 12.6ms\n",
      "Speed: 1.9ms preprocess, 12.6ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Processed: IMG20241029122404.jpg -> output_results\\IMG20241029122404.jpg\n",
      "\n",
      "0: 640x512 1 Saffron_Top, 13.0ms\n",
      "Speed: 1.9ms preprocess, 13.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed: IMG20241029122428.jpg -> output_results\\IMG20241029122428.jpg\n",
      "\n",
      "0: 640x512 1 Saffron_Top, 13.3ms\n",
      "Speed: 2.1ms preprocess, 13.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed: IMG20241029122442.jpg -> output_results\\IMG20241029122442.jpg\n",
      "\n",
      "0: 640x512 1 Saffron_Top, 12.5ms\n",
      "Speed: 1.8ms preprocess, 12.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed: IMG20241029122445.jpg -> output_results\\IMG20241029122445.jpg\n",
      "\n",
      "0: 640x512 1 Saffron_Top, 12.5ms\n",
      "Speed: 1.9ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed: IMG20241029122447.jpg -> output_results\\IMG20241029122447.jpg\n",
      "\n",
      "0: 640x512 2 Saffron_Tops, 12.9ms\n",
      "Speed: 2.0ms preprocess, 12.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed: IMG20241029122455.jpg -> output_results\\IMG20241029122455.jpg\n",
      "\n",
      "0: 640x512 1 Saffron_Top, 12.6ms\n",
      "Speed: 2.5ms preprocess, 12.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed: IMG20241029122500.jpg -> output_results\\IMG20241029122500.jpg\n",
      "\n",
      "0: 640x512 2 Saffron_Tops, 18.8ms\n",
      "Speed: 2.1ms preprocess, 18.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed: IMG20241029122525.jpg -> output_results\\IMG20241029122525.jpg\n",
      "\n",
      "0: 640x512 (no detections), 19.0ms\n",
      "Speed: 2.3ms preprocess, 19.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed: IMG20241029122620.jpg -> output_results\\IMG20241029122620.jpg\n",
      "\n",
      "0: 640x512 (no detections), 19.2ms\n",
      "Speed: 1.8ms preprocess, 19.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed: IMG20241029122624.jpg -> output_results\\IMG20241029122624.jpg\n",
      "\n",
      "0: 512x640 (no detections), 20.4ms\n",
      "Speed: 1.7ms preprocess, 20.4ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Processed: IMG20241029122629.jpg -> output_results\\IMG20241029122629.jpg\n",
      "\n",
      "0: 512x640 1 Saffron_Top, 20.3ms\n",
      "Speed: 1.9ms preprocess, 20.3ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Processed: IMG20241029122632.jpg -> output_results\\IMG20241029122632.jpg\n",
      "\n",
      "0: 640x512 4 Saffron_Tops, 21.4ms\n",
      "Speed: 2.7ms preprocess, 21.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed: IMG20241029123112.jpg -> output_results\\IMG20241029123112.jpg\n",
      "\n",
      "0: 640x512 5 Saffron_Tops, 20.7ms\n",
      "Speed: 2.2ms preprocess, 20.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed: IMG20241029123145.jpg -> output_results\\IMG20241029123145.jpg\n",
      "\n",
      "0: 640x512 1 Saffron_Top, 12.3ms\n",
      "Speed: 1.7ms preprocess, 12.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed: IMG20241029123149.jpg -> output_results\\IMG20241029123149.jpg\n",
      "\n",
      "0: 640x512 1 Saffron_Top, 12.3ms\n",
      "Speed: 1.8ms preprocess, 12.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Processed: IMG20241029123513.jpg -> output_results\\IMG20241029123513.jpg\n",
      "✅ All images processed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "from ultralytics import YOLO\n",
    "import timm  # for HRNet-W18 backbone\n",
    "\n",
    "# -------------------------------\n",
    "# HRNet-W18 definition\n",
    "# -------------------------------\n",
    "class HRNet(nn.Module):\n",
    "    def __init__(self, num_keypoints=1, backbone=\"hrnet_w18\", head_hidden=512):\n",
    "        super(HRNet, self).__init__()\n",
    "        self.backbone = timm.create_model(backbone, pretrained=True, num_classes=0)  # remove classifier\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(self.backbone.num_features, head_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(head_hidden, num_keypoints*2)  # output normalized x,y\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        feat = self.backbone(x)\n",
    "        out = self.head(feat)\n",
    "        return torch.sigmoid(out)  # normalized 0-1\n",
    "\n",
    "def preprocess_img(img, img_size=640):\n",
    "    transform = T.Compose([\n",
    "        T.ToPILImage(),\n",
    "        T.Resize((img_size, img_size)),\n",
    "        T.ToTensor(),\n",
    "    ])\n",
    "    return transform(img).unsqueeze(0)\n",
    "\n",
    "# -------------------------------\n",
    "# CONFIG\n",
    "# -------------------------------\n",
    "yolo_model_path = \"E:/Project_Work/2025/Saffron_Project/Github_Code/Saffron_Detection/YoloV8+HRNet/YoloV8_Result_Object_detection/Result_Weight/detect/weights/best.pt\"\n",
    "hrnet_model_path = \"hrnet_pluck_best.pth\"\n",
    "input_folder = \"E:/Project_Work/2025/Saffron_Project/Github_Code/Saffron_Detection/YoloV8+HRNet/YoloV8_Result_Object_detection/test/images_field\"\n",
    "output_folder = \"output_results\"\n",
    "confidence_thresh = 0.30\n",
    "img_size = 640\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# -------------------------------\n",
    "# LOAD MODELS\n",
    "# -------------------------------\n",
    "yolo = YOLO(yolo_model_path)\n",
    "\n",
    "checkpoint = torch.load(hrnet_model_path, map_location=device)\n",
    "state_dict = checkpoint.get(\"model\", checkpoint)\n",
    "\n",
    "hrnet = HRNet(num_keypoints=1, backbone=\"hrnet_w18\", head_hidden=512).to(device)\n",
    "hrnet.load_state_dict(state_dict, strict=False)\n",
    "hrnet.eval()\n",
    "\n",
    "# -------------------------------\n",
    "# INFERENCE LOOP\n",
    "# -------------------------------\n",
    "for file in os.listdir(input_folder):\n",
    "    if not file.lower().endswith((\".jpg\", \".png\", \".jpeg\")):\n",
    "        continue\n",
    "    \n",
    "    img_path = os.path.join(input_folder, file)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        continue\n",
    "\n",
    "    results = yolo(img)[0]\n",
    "    for box in results.boxes:\n",
    "        conf = float(box.conf[0])\n",
    "        cls = int(box.cls[0])\n",
    "        if conf < confidence_thresh:\n",
    "            continue\n",
    "        \n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        crop = img[y1:y2, x1:x2]\n",
    "        if crop.size == 0:\n",
    "            continue\n",
    "\n",
    "        inp = preprocess_img(crop, img_size=img_size).to(device)\n",
    "        with torch.no_grad():\n",
    "            kp = hrnet(inp).cpu().numpy()[0]  # shape [2] normalized x,y\n",
    "\n",
    "        cx = int(x1 + kp[0] * (x2 - x1))\n",
    "        cy = int(y1 + kp[1] * (y2 - y1))\n",
    "\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(img, f\"YOLO conf: {conf:.2f}\", (x1, y1-10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)\n",
    "        cv2.circle(img, (cx, cy), 5, (0,0,255), -1)\n",
    "        cv2.putText(img, \"Pluck\", (cx+5, cy), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 2)\n",
    "\n",
    "    save_path = os.path.join(output_folder, file)\n",
    "    cv2.imwrite(save_path, img)\n",
    "    print(f\"Processed: {file} -> {save_path}\")\n",
    "\n",
    "print(\"✅ All images processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6511ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6646abac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov11_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
